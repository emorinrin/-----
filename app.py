# main.py
import streamlit as st
import google.generativeai as genai
import PyPDF2
from langchain.text_splitter import RecursiveCharacterTextSplitter
import time
import io
import docx # docxãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ‰±ã†ãŸã‚ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ

# --- ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®åŸºæœ¬è¨­å®š ---
st.set_page_config(
    page_title="é•·æ–‡PDFç¿»è¨³ã‚¢ãƒ—ãƒª",
    page_icon="ğŸ“–",
    layout="wide"
)

# --- é–¢æ•°å®šç¾© ---

@st.cache_data(show_spinner=False)
def extract_text_from_pdf(uploaded_file):
    """
    ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸPDFãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã™ã‚‹é–¢æ•°
    """
    try:
        reader = PyPDF2.PdfReader(uploaded_file)
        text = ""
        for page in reader.pages:
            page_text = page.extract_text()
            if page_text:
                text += page_text
        return text
    except Exception as e:
        st.error(f"PDFã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None

def translate_text(text_chunk, api_key, model_name="gemini-1.5-flash"):
    """
    Google Gemini APIã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ã‚¯ã‚’ç¿»è¨³ã™ã‚‹é–¢æ•°
    """
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel(model_name)
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®è¨­è¨ˆï¼šã‚ˆã‚Šè‡ªç„¶ãªç¿»è¨³ã‚’ä¿ƒã™æŒ‡ç¤ºã‚’è¿½åŠ 
        prompt = f"""
        ã‚ãªãŸã¯ãƒ—ãƒ­ã®ç¿»è¨³å®¶ã§ã™ã€‚ä»¥ä¸‹ã®è‹±æ–‡ã‚’ã€æ–‡è„ˆã‚’è€ƒæ…®ã—ã€è‡ªç„¶ã§æµæš¢ãªæ—¥æœ¬èªã«ç¿»è¨³ã—ã¦ãã ã•ã„ã€‚
        å°‚é–€ç”¨èªã¯æ­£ç¢ºã«è¨³ã—ã€å…ƒã®æ–‡ç« ã®æ„å›³ã‚„ãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ã‚’å¿ å®Ÿã«å†ç¾ã—ã¦ãã ã•ã„ã€‚
        åŸæ–‡ã«é–¢ã™ã‚‹è§£èª¬ãªã©ã®è¿½åŠ æƒ…å ±ã‚„å‰ç½®ãã¯ä¸è¦ã§ã™ã€‚

        ---
        English Text:
        {text_chunk}
        ---

        Japanese Translation:
        """
        
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        # APIã‚¨ãƒ©ãƒ¼ã®è©³ç´°ã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
        return f"ç¿»è¨³ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"

# --- Streamlit UI ---

st.title("ğŸ“– é•·æ–‡PDFç¿»è¨³ã‚¢ãƒ—ãƒª")
st.markdown("100ãƒšãƒ¼ã‚¸ã‚’è¶…ãˆã‚‹ã‚ˆã†ãªé•·æ–‡ã®è‹±æ–‡PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã€Googleã®Geminiãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ã¦æ—¥æœ¬èªã«ç¿»è¨³ã—ã¾ã™ã€‚")
st.markdown("---")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
with st.sidebar:
    st.header("è¨­å®š")
    api_key = st.text_input("Google AI Studio APIã‚­ãƒ¼", type="password")
    st.markdown("[APIã‚­ãƒ¼ã®å–å¾—æ–¹æ³•](https://aistudio.google.com/app/apikey)", unsafe_allow_html=True)
    
    model_name = st.selectbox(
        "ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«",
        ("gemini-1.5-flash", "gemini-1.5-pro", "gemini-2.5-pro"),
        help="é€šå¸¸ã¯`gemini-1.5-flash`ãŒé«˜é€Ÿã‹ã¤ååˆ†ãªæ€§èƒ½ã§ãŠã™ã™ã‚ã§ã™ã€‚"
    )
    
    chunk_size = st.slider(
        "ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º", 500, 5000, 1500, 100,
        help="ä¸€åº¦ã«ç¿»è¨³ã™ã‚‹æ–‡å­—æ•°ã€‚å¤§ãã„ã»ã©æ–‡è„ˆã‚’ç¶­æŒã§ãã¾ã™ãŒã€APIã®åˆ¶é™ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚"
    )
    chunk_overlap = st.slider(
        "ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—", 0, 500, 200, 50,
        help="ãƒãƒ£ãƒ³ã‚¯é–“ã®é‡è¤‡æ–‡å­—æ•°ã€‚æ–‡è„ˆã®é€£ç¶šæ€§ã‚’é«˜ã‚ã¾ã™ã€‚"
    )

# --- ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ ---
uploaded_file = st.file_uploader(
    "ç¿»è¨³ã—ãŸã„è‹±æ–‡ã®PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„",
    type="pdf",
    accept_multiple_files=False
)

if 'translated_text' not in st.session_state:
    st.session_state.translated_text = ""
if 'original_text' not in st.session_state:
    st.session_state.original_text = ""

if uploaded_file:
    if st.button("ç¿»è¨³é–‹å§‹", type="primary"):
        # åˆæœŸåŒ–
        st.session_state.translated_text = ""
        st.session_state.original_text = ""

        # 1. PDFã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
        with st.spinner("PDFã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºä¸­..."):
            original_text = extract_text_from_pdf(uploaded_file)
            st.session_state.original_text = original_text

        if original_text:
            st.success("ãƒ†ã‚­ã‚¹ãƒˆã®æŠ½å‡ºãŒå®Œäº†ã—ã¾ã—ãŸã€‚ç¿»è¨³ã‚’é–‹å§‹ã—ã¾ã™ã€‚")

            # 2. ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=chunk_size,
                chunk_overlap=chunk_overlap,
                length_function=len,
            )
            chunks = text_splitter.split_text(original_text)
            total_chunks = len(chunks)

            # 3. ãƒãƒ£ãƒ³ã‚¯ã‚’é †ç•ªã«ç¿»è¨³
            progress_bar = st.progress(0, "ç¿»è¨³ã®é€²æ—")
            translated_chunks = []
            
            # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤ºç”¨ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼
            realtime_display = st.empty()
            
            start_time = time.time()

            for i, chunk in enumerate(chunks):
                # ç¿»è¨³å®Ÿè¡Œ
                translated_chunk = translate_text(chunk, api_key, model_name)
                translated_chunks.append(translated_chunk)
                
                # é€²æ—ã¨ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤ºã®æ›´æ–°
                progress_value = (i + 1) / total_chunks
                progress_text = f"ç¿»è¨³ã®é€²æ—: {i+1}/{total_chunks} ãƒãƒ£ãƒ³ã‚¯å®Œäº†"
                progress_bar.progress(progress_value, text=progress_text)
                
                # ç¿»è¨³æ¸ˆã¿ãƒ†ã‚­ã‚¹ãƒˆã‚’çµåˆã—ã¦ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤º
                realtime_display.text_area(
                    "ç¿»è¨³çµæœï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°ï¼‰", 
                    "".join(translated_chunks), 
                    height=400
                )
                
                # APIã®ãƒ¬ãƒ¼ãƒˆãƒªãƒŸãƒƒãƒˆå¯¾ç­–
                time.sleep(1) 

            end_time = time.time()
            processing_time = end_time - start_time
            
            st.session_state.translated_text = "".join(translated_chunks)
            progress_bar.empty() # å®Œäº†ã—ãŸã‚‰ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’æ¶ˆã™
            st.success(f"ç¿»è¨³ãŒå®Œäº†ã—ã¾ã—ãŸï¼ï¼ˆå‡¦ç†æ™‚é–“: {processing_time:.2f}ç§’ï¼‰")

# ç¿»è¨³çµæœã®è¡¨ç¤ºã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
if st.session_state.translated_text:
    st.subheader("æœ€çµ‚ç¿»è¨³çµæœ")
    st.text_area(
        "ç¿»è¨³å…¨æ–‡",
        st.session_state.translated_text,
        height=600
    )
    
    st.subheader("ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")

    # --- docxãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯ ---
    doc = docx.Document()
    doc.add_heading(f"{uploaded_file.name} ã®ç¿»è¨³çµæœ", 0)
    doc.add_paragraph(st.session_state.translated_text)
    
    # ãƒ¡ãƒ¢ãƒªä¸Šã§docxãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ‰±ã†
    bio = io.BytesIO()
    doc.save(bio)
    bio.seek(0)
    # --------------------------------

    col1, col2 = st.columns(2)
    with col1:
        st.download_button(
            label="ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ« (.txt)",
            data=st.session_state.translated_text.encode('utf-8'),
            file_name=f"{uploaded_file.name.replace('.pdf', '')}_translated.txt",
            mime="text/plain",
            use_container_width=True
        )
    with col2:
        st.download_button(
            label="Wordãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ (.docx)",
            data=bio,
            file_name=f"{uploaded_file.name.replace('.pdf', '')}_translated.docx",
            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
            use_container_width=True
        )


    with st.expander("åŸæ–‡ã‚’è¡¨ç¤º"):
        st.text_area("æŠ½å‡ºã•ã‚ŒãŸåŸæ–‡", st.session_state.original_text, height=400)
